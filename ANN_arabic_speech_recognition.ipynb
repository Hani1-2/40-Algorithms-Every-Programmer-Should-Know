{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tpkOgeuJO7kqbEy1d8hyl_1Ag_rB2XQI",
      "authorship_tag": "ABX9TyMscvlgCp28+EBiNUHObVTZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/40-Algorithms-Every-Programmer-Should-Know/blob/master/ANN_arabic_speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2qJNKrQRgBdi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data_path = '/content/drive/MyDrive/FYP-Code/data_prep_ann.json'\n",
        "with open(data_path, \"r\") as fp:\n",
        "      data = json.load(fp)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "j9GxcnCegyH3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "X=np.array(data['MFCCs'])\n",
        "y=np.array(data['labels'])"
      ],
      "metadata": {
        "id": "BL5mZgo6gYR1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx2p9OOfmGGE",
        "outputId": "b68b796f-f9bd-441b-a3c7-20807649caf2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21952, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAB-FIxCmlbh",
        "outputId": "a3bcde71-0749-4b2a-912b-4ac9cf1105bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21952,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Label Encoding\n",
        "###y=np.array(pd.get_dummies(y))\n",
        "### Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))"
      ],
      "metadata": {
        "id": "yMil2AZsmNip"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RLSR_8FmP4s",
        "outputId": "b995f48c-eb7a-4bca-8fbe-e471c0f8b6d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21952, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "jGRQ3yd2gz0Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4PUuufvg8rL",
        "outputId": "8d769506-bc68-4c4a-81d5-ac45780e442e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17561, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyQJYSHLhAUd",
        "outputId": "298eedb2-4b9c-48b9-9bea-1e2e5b358c7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17561, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "3RRywx02hJof"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "from keras import layers\n",
        "from keras import layers\n",
        "import keras"
      ],
      "metadata": {
        "id": "rTRS2PVsjK37"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "# define a custom loss function that incorporates the confidence score\n",
        "def confidence_loss(y_true, y_pred, conf_weight=1.0):\n",
        "    # compute the cross-entropy loss\n",
        "    cross_entropy = keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # compute the confidence score\n",
        "    confidence = K.max(y_pred, axis=-1)\n",
        "\n",
        "    # combine the cross-entropy loss and confidence score into a single loss\n",
        "    loss = cross_entropy + conf_weight * (1 - confidence)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "9MQUOmKg_D0e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate predictions and confidence scores\n",
        "def predict_with_confidence(model, x):\n",
        "    # generate predictions and confidence scores for each input\n",
        "    preds = model.predict(x)\n",
        "    confs = np.max(preds, axis=-1)\n",
        "    print('preds',preds)\n",
        "    print('confidence score',confs)\n",
        "    return preds, confs"
      ],
      "metadata": {
        "id": "PF7x5Xgg_TqK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(28, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss=confidence_loss,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aew9_8l2hWN7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1epOckoYhaEX",
        "outputId": "b22e8f4f-90fb-4290-c633-e8418e6cafe4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 256)               10496     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 28)                1820      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,468\n",
            "Trainable params: 53,468\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trianing my model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 50\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='audio_classification.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXq05kRZhm4D",
        "outputId": "53811b1a-d03e-4d11-ef4f-3d54a55cc941"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "543/549 [============================>.] - ETA: 0s - loss: 3.2925 - accuracy: 0.2584\n",
            "Epoch 1: val_loss improved from inf to 2.02934, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 3s 4ms/step - loss: 3.2788 - accuracy: 0.2605 - val_loss: 2.0293 - val_accuracy: 0.4634\n",
            "Epoch 2/50\n",
            "535/549 [============================>.] - ETA: 0s - loss: 1.6958 - accuracy: 0.5453\n",
            "Epoch 2: val_loss improved from 2.02934 to 1.37214, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 1.6851 - accuracy: 0.5482 - val_loss: 1.3721 - val_accuracy: 0.6185\n",
            "Epoch 3/50\n",
            "539/549 [============================>.] - ETA: 0s - loss: 1.1580 - accuracy: 0.6859\n",
            "Epoch 3: val_loss improved from 1.37214 to 1.04385, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 1.1561 - accuracy: 0.6867 - val_loss: 1.0439 - val_accuracy: 0.7094\n",
            "Epoch 4/50\n",
            "546/549 [============================>.] - ETA: 0s - loss: 0.8384 - accuracy: 0.7764\n",
            "Epoch 4: val_loss improved from 1.04385 to 0.73483, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.8372 - accuracy: 0.7767 - val_loss: 0.7348 - val_accuracy: 0.8098\n",
            "Epoch 5/50\n",
            "529/549 [===========================>..] - ETA: 0s - loss: 0.5932 - accuracy: 0.8438\n",
            "Epoch 5: val_loss improved from 0.73483 to 0.60406, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 5ms/step - loss: 0.5968 - accuracy: 0.8429 - val_loss: 0.6041 - val_accuracy: 0.8474\n",
            "Epoch 6/50\n",
            "535/549 [============================>.] - ETA: 0s - loss: 0.4342 - accuracy: 0.8856\n",
            "Epoch 6: val_loss improved from 0.60406 to 0.51844, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.4327 - accuracy: 0.8859 - val_loss: 0.5184 - val_accuracy: 0.8622\n",
            "Epoch 7/50\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.9104\n",
            "Epoch 7: val_loss improved from 0.51844 to 0.41362, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.3395 - accuracy: 0.9105 - val_loss: 0.4136 - val_accuracy: 0.8959\n",
            "Epoch 8/50\n",
            "539/549 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9341\n",
            "Epoch 8: val_loss improved from 0.41362 to 0.25598, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.2534 - accuracy: 0.9344 - val_loss: 0.2560 - val_accuracy: 0.9299\n",
            "Epoch 9/50\n",
            "544/549 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9480\n",
            "Epoch 9: val_loss did not improve from 0.25598\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.2038 - accuracy: 0.9480 - val_loss: 0.3337 - val_accuracy: 0.9125\n",
            "Epoch 10/50\n",
            "542/549 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9538\n",
            "Epoch 10: val_loss improved from 0.25598 to 0.21648, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.1841 - accuracy: 0.9537 - val_loss: 0.2165 - val_accuracy: 0.9412\n",
            "Epoch 11/50\n",
            "542/549 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9639\n",
            "Epoch 11: val_loss improved from 0.21648 to 0.20227, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.1393 - accuracy: 0.9638 - val_loss: 0.2023 - val_accuracy: 0.9465\n",
            "Epoch 12/50\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9654\n",
            "Epoch 12: val_loss improved from 0.20227 to 0.18127, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.1355 - accuracy: 0.9654 - val_loss: 0.1813 - val_accuracy: 0.9517\n",
            "Epoch 13/50\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9678\n",
            "Epoch 13: val_loss did not improve from 0.18127\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.1282 - accuracy: 0.9670 - val_loss: 0.2340 - val_accuracy: 0.9394\n",
            "Epoch 14/50\n",
            "547/549 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9719\n",
            "Epoch 14: val_loss improved from 0.18127 to 0.15847, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.1147 - accuracy: 0.9719 - val_loss: 0.1585 - val_accuracy: 0.9606\n",
            "Epoch 15/50\n",
            "547/549 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9724\n",
            "Epoch 15: val_loss improved from 0.15847 to 0.15781, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.1075 - accuracy: 0.9724 - val_loss: 0.1578 - val_accuracy: 0.9613\n",
            "Epoch 16/50\n",
            "537/549 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9742\n",
            "Epoch 16: val_loss improved from 0.15781 to 0.11777, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.1010 - accuracy: 0.9742 - val_loss: 0.1178 - val_accuracy: 0.9724\n",
            "Epoch 17/50\n",
            "535/549 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9713\n",
            "Epoch 17: val_loss did not improve from 0.11777\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.1085 - accuracy: 0.9714 - val_loss: 0.1442 - val_accuracy: 0.9642\n",
            "Epoch 18/50\n",
            "527/549 [===========================>..] - ETA: 0s - loss: 0.0942 - accuracy: 0.9750\n",
            "Epoch 18: val_loss improved from 0.11777 to 0.08073, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0933 - accuracy: 0.9753 - val_loss: 0.0807 - val_accuracy: 0.9797\n",
            "Epoch 19/50\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9871\n",
            "Epoch 19: val_loss did not improve from 0.08073\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0541 - accuracy: 0.9869 - val_loss: 0.3694 - val_accuracy: 0.9189\n",
            "Epoch 20/50\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9751\n",
            "Epoch 20: val_loss did not improve from 0.08073\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.1069 - accuracy: 0.9752 - val_loss: 0.1095 - val_accuracy: 0.9720\n",
            "Epoch 21/50\n",
            "529/549 [===========================>..] - ETA: 0s - loss: 0.0893 - accuracy: 0.9780\n",
            "Epoch 21: val_loss did not improve from 0.08073\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0891 - accuracy: 0.9780 - val_loss: 0.1127 - val_accuracy: 0.9743\n",
            "Epoch 22/50\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9760\n",
            "Epoch 22: val_loss did not improve from 0.08073\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.1014 - accuracy: 0.9755 - val_loss: 0.0875 - val_accuracy: 0.9781\n",
            "Epoch 23/50\n",
            "546/549 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9826\n",
            "Epoch 23: val_loss improved from 0.08073 to 0.07609, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.9827 - val_loss: 0.0761 - val_accuracy: 0.9843\n",
            "Epoch 24/50\n",
            "536/549 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9872\n",
            "Epoch 24: val_loss did not improve from 0.07609\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0561 - accuracy: 0.9867 - val_loss: 0.1550 - val_accuracy: 0.9640\n",
            "Epoch 25/50\n",
            "544/549 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9821\n",
            "Epoch 25: val_loss improved from 0.07609 to 0.06822, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.0682 - val_accuracy: 0.9825\n",
            "Epoch 26/50\n",
            "538/549 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9901\n",
            "Epoch 26: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0400 - accuracy: 0.9898 - val_loss: 0.1126 - val_accuracy: 0.9754\n",
            "Epoch 27/50\n",
            "532/549 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9784\n",
            "Epoch 27: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0893 - accuracy: 0.9782 - val_loss: 0.1793 - val_accuracy: 0.9629\n",
            "Epoch 28/50\n",
            "532/549 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9851\n",
            "Epoch 28: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0632 - accuracy: 0.9852 - val_loss: 0.0718 - val_accuracy: 0.9866\n",
            "Epoch 29/50\n",
            "531/549 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9865\n",
            "Epoch 29: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0591 - accuracy: 0.9863 - val_loss: 0.1113 - val_accuracy: 0.9722\n",
            "Epoch 30/50\n",
            "530/549 [===========================>..] - ETA: 0s - loss: 0.0713 - accuracy: 0.9841\n",
            "Epoch 30: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0711 - accuracy: 0.9843 - val_loss: 0.1027 - val_accuracy: 0.9734\n",
            "Epoch 31/50\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9860\n",
            "Epoch 31: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0573 - accuracy: 0.9860 - val_loss: 0.1061 - val_accuracy: 0.9745\n",
            "Epoch 32/50\n",
            "543/549 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9862\n",
            "Epoch 32: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0580 - accuracy: 0.9861 - val_loss: 0.1468 - val_accuracy: 0.9647\n",
            "Epoch 33/50\n",
            "539/549 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9856\n",
            "Epoch 33: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9857 - val_loss: 0.0728 - val_accuracy: 0.9825\n",
            "Epoch 34/50\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9850\n",
            "Epoch 34: val_loss did not improve from 0.06822\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9850 - val_loss: 0.1240 - val_accuracy: 0.9752\n",
            "Epoch 35/50\n",
            "537/549 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9873\n",
            "Epoch 35: val_loss improved from 0.06822 to 0.05103, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0534 - accuracy: 0.9874 - val_loss: 0.0510 - val_accuracy: 0.9929\n",
            "Epoch 36/50\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9872\n",
            "Epoch 36: val_loss did not improve from 0.05103\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.9872 - val_loss: 0.0669 - val_accuracy: 0.9854\n",
            "Epoch 37/50\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9848\n",
            "Epoch 37: val_loss did not improve from 0.05103\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0706 - accuracy: 0.9848 - val_loss: 0.1459 - val_accuracy: 0.9718\n",
            "Epoch 38/50\n",
            "531/549 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9936\n",
            "Epoch 38: val_loss improved from 0.05103 to 0.03667, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.0367 - val_accuracy: 0.9918\n",
            "Epoch 39/50\n",
            "537/549 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9890\n",
            "Epoch 39: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0487 - accuracy: 0.9888 - val_loss: 0.0808 - val_accuracy: 0.9843\n",
            "Epoch 40/50\n",
            "539/549 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9843\n",
            "Epoch 40: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0723 - accuracy: 0.9843 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 41/50\n",
            "547/549 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9876\n",
            "Epoch 41: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.9876 - val_loss: 0.0508 - val_accuracy: 0.9893\n",
            "Epoch 42/50\n",
            "544/549 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9904\n",
            "Epoch 42: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0400 - accuracy: 0.9904 - val_loss: 0.1638 - val_accuracy: 0.9688\n",
            "Epoch 43/50\n",
            "547/549 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9869\n",
            "Epoch 43: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0875 - val_accuracy: 0.9784\n",
            "Epoch 44/50\n",
            "545/549 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9931\n",
            "Epoch 44: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0305 - accuracy: 0.9932 - val_loss: 0.0385 - val_accuracy: 0.9913\n",
            "Epoch 45/50\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9879\n",
            "Epoch 45: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0582 - accuracy: 0.9874 - val_loss: 0.1603 - val_accuracy: 0.9693\n",
            "Epoch 46/50\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9863\n",
            "Epoch 46: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0641 - accuracy: 0.9859 - val_loss: 0.1651 - val_accuracy: 0.9677\n",
            "Epoch 47/50\n",
            "546/549 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9898\n",
            "Epoch 47: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0418 - accuracy: 0.9899 - val_loss: 0.0417 - val_accuracy: 0.9904\n",
            "Epoch 48/50\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9885\n",
            "Epoch 48: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0564 - accuracy: 0.9886 - val_loss: 0.0591 - val_accuracy: 0.9882\n",
            "Epoch 49/50\n",
            "543/549 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9953\n",
            "Epoch 49: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 0.0464 - val_accuracy: 0.9900\n",
            "Epoch 50/50\n",
            "544/549 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.9847\n",
            "Epoch 50: val_loss did not improve from 0.03667\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9848 - val_loss: 0.1066 - val_accuracy: 0.9809\n",
            "Training completed in time:  0:01:37.495498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiGYCxlZWYMr",
        "outputId": "ef974e71-5fa6-490a-cf9a-79cce0bd4778"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9808699488639832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"007.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "print(mfccs_scaled_features)\n",
        "print(mfccs_scaled_features.shape)\n",
        "predicted_label=model.predict(mfccs_scaled_features)\n",
        "print(predicted_label)\n",
        "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "# prediction_class\n",
        "y_classes = np.argmax(predicted_label, axis=-1)\n",
        "print(y_classes,'y_classes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2nGySBGnJD_",
        "outputId": "7da19c37-6181-4be1-90df-2441a71924fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.6688876e+02  1.6920772e+02  1.5943729e+01  2.9220087e+01\n",
            "  9.9509230e+00  9.4693556e+00  4.4155707e+00  2.2081059e+01\n",
            " -8.4803972e+00 -1.0236913e+01 -9.6969500e+00 -1.3531391e+01\n",
            " -1.6008681e-01 -9.6199722e+00  4.0289865e+00 -1.1860269e+01\n",
            " -8.8936329e+00 -7.5885506e+00 -1.0422292e+01 -2.9442387e-04\n",
            " -7.9004889e+00  1.6884052e+00 -4.2548723e+00 -1.7290313e+00\n",
            " -2.5600350e+00 -7.0732765e+00 -3.4278486e+00 -7.8612771e+00\n",
            " -2.2507224e+00 -3.7321632e+00 -1.2287372e+00 -2.7821176e+00\n",
            " -5.1131840e+00 -2.4848039e+00 -3.3958735e+00 -2.2556162e+00\n",
            " -9.0258640e-01  5.2021070e+00  6.4245253e+00  5.1930232e+00]\n",
            "[[-2.6688876e+02  1.6920772e+02  1.5943729e+01  2.9220087e+01\n",
            "   9.9509230e+00  9.4693556e+00  4.4155707e+00  2.2081059e+01\n",
            "  -8.4803972e+00 -1.0236913e+01 -9.6969500e+00 -1.3531391e+01\n",
            "  -1.6008681e-01 -9.6199722e+00  4.0289865e+00 -1.1860269e+01\n",
            "  -8.8936329e+00 -7.5885506e+00 -1.0422292e+01 -2.9442387e-04\n",
            "  -7.9004889e+00  1.6884052e+00 -4.2548723e+00 -1.7290313e+00\n",
            "  -2.5600350e+00 -7.0732765e+00 -3.4278486e+00 -7.8612771e+00\n",
            "  -2.2507224e+00 -3.7321632e+00 -1.2287372e+00 -2.7821176e+00\n",
            "  -5.1131840e+00 -2.4848039e+00 -3.3958735e+00 -2.2556162e+00\n",
            "  -9.0258640e-01  5.2021070e+00  6.4245253e+00  5.1930232e+00]]\n",
            "(1, 40)\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "[[1.72372385e-30 0.00000000e+00 4.05592748e-14 4.68427033e-12\n",
            "  2.60956540e-13 9.50304063e-26 1.00000000e+00 1.15857476e-29\n",
            "  6.96747195e-25 1.18537695e-08 1.54623238e-23 1.13569969e-11\n",
            "  1.42754473e-32 5.37053766e-36 8.76973529e-15 1.52033238e-32\n",
            "  3.77697160e-22 3.38228983e-20 7.72169806e-20 3.44120609e-20\n",
            "  9.97052531e-22 5.35779772e-18 8.27109173e-22 2.24466219e-16\n",
            "  1.80473202e-15 4.57024392e-13 7.48540936e-28 2.70379996e-10]]\n",
            "[6] y_classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['mapping'][6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ibpJRHtioL_q",
        "outputId": "48438613-d8fb-402e-d5c6-e95476c485ee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rabbil'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### when model predict correct output, it gives 1. confidence. Other than that confidence for the words on which the has not trained is less than 90"
      ],
      "metadata": {
        "id": "TUWc14CnFUEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"004.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "print(mfccs_scaled_features)\n",
        "print(mfccs_scaled_features.shape)\n",
        "predicted_label=predict_with_confidence(model,mfccs_scaled_features)\n",
        "# print(predicted_label,'predicted label')\n",
        "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "# prediction_class\n",
        "y_classes = np.argmax(predicted_label[0], axis=-1)\n",
        "print(y_classes,'predicted label')"
      ],
      "metadata": {
        "id": "Zz3UrNcrpCMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ec968f-f2c0-434f-b4cc-e6b45259af76"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.13894287e+02  1.21448944e+02 -1.58409843e+01  4.44018517e+01\n",
            " -4.30620308e+01  1.04552956e+01 -7.70796394e+00  1.93449631e+01\n",
            " -1.54493647e+01 -5.64498568e+00 -2.62555623e+00 -5.63413095e+00\n",
            " -4.70574617e+00 -1.69100113e+01  2.85181732e+01 -2.02912216e+01\n",
            "  5.73039150e+00  2.51097989e+00 -1.72864075e+01  3.65360522e+00\n",
            " -1.08147669e+01 -1.24511704e-01 -7.63013458e+00 -3.31317997e+00\n",
            " -8.56130791e+00  6.79593515e+00  1.12333384e+01  2.01670227e+01\n",
            "  3.11204929e+01  1.60158119e+01  1.81351357e+01  5.09372234e+00\n",
            "  2.43120146e+00 -8.13832760e+00 -6.95227206e-01  2.06990838e+00\n",
            " -5.34135342e+00  2.19039202e+00 -4.89979362e+00 -1.13116610e+00]\n",
            "[[-3.13894287e+02  1.21448944e+02 -1.58409843e+01  4.44018517e+01\n",
            "  -4.30620308e+01  1.04552956e+01 -7.70796394e+00  1.93449631e+01\n",
            "  -1.54493647e+01 -5.64498568e+00 -2.62555623e+00 -5.63413095e+00\n",
            "  -4.70574617e+00 -1.69100113e+01  2.85181732e+01 -2.02912216e+01\n",
            "   5.73039150e+00  2.51097989e+00 -1.72864075e+01  3.65360522e+00\n",
            "  -1.08147669e+01 -1.24511704e-01 -7.63013458e+00 -3.31317997e+00\n",
            "  -8.56130791e+00  6.79593515e+00  1.12333384e+01  2.01670227e+01\n",
            "   3.11204929e+01  1.60158119e+01  1.81351357e+01  5.09372234e+00\n",
            "   2.43120146e+00 -8.13832760e+00 -6.95227206e-01  2.06990838e+00\n",
            "  -5.34135342e+00  2.19039202e+00 -4.89979362e+00 -1.13116610e+00]]\n",
            "(1, 40)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "preds [[1.3335799e-33 0.0000000e+00 0.0000000e+00 1.0000000e+00 2.5746753e-32\n",
            "  5.8446448e-30 4.9304586e-38 7.1156045e-18 0.0000000e+00 5.6924333e-11\n",
            "  0.0000000e+00 1.4890592e-36 7.8161256e-18 4.3575728e-32 1.6322346e-34\n",
            "  6.6426648e-29 1.7020989e-19 3.7372287e-37 1.1988513e-19 4.4119710e-15\n",
            "  2.1401882e-32 3.6414605e-23 0.0000000e+00 2.6079533e-28 7.0514953e-37\n",
            "  0.0000000e+00 3.9034613e-27 2.9560576e-19]]\n",
            "confidence score [1.]\n",
            "[3] predicted label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['mapping'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j36erf7CNB0V",
        "outputId": "df46f932-95b1-4198-bbad-4800e0fb0b0f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Al-raheemi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### for incorrect word"
      ],
      "metadata": {
        "id": "vp6l2VvgFpGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"test3.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "# print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "# print(mfccs_scaled_features)\n",
        "# print(mfccs_scaled_features.shape)\n",
        "predicted_label=predict_with_confidence(model,mfccs_scaled_features)\n",
        "# print(predicted_label,'predicted label')\n",
        "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "# prediction_class\n",
        "y_classes = np.argmax(predicted_label[0], axis=-1)\n",
        "print(y_classes,'predicted label')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxdnsxQtA2uM",
        "outputId": "911f506b-ad79-4b2f-e508-b89a5afa4fc7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "preds [[0.00000000e+00 0.00000000e+00 1.78855838e-17 0.00000000e+00\n",
            "  1.36379804e-38 0.00000000e+00 1.40822305e-30 0.00000000e+00\n",
            "  8.95489872e-01 7.66893690e-33 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 5.63906467e-16 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.04510166e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 2.45481954e-16 0.00000000e+00 2.98184979e-12]]\n",
            "confidence score [0.8954899]\n",
            "[8] predicted label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBCnMEmHFuXA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}